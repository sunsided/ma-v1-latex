\documentclass[a4paper, 11pt, english, ngerman]{article}

\usepackage{eurosym}
\usepackage{geometry}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage[figurewithin=section, 
		   font=small, 
		   labelfont=bf]
		   {caption}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{inconsolata}
\usepackage{lmodern}
\usepackage[english,ngerman]{babel}
\usepackage{xspace}

\usepackage[super]{nth}
\usepackage{makeidx}

\usepackage{amsmath}
\usepackage{bm}
\usepackage{isomath}
\usepackage{xfrac}
\usepackage{cancel}

\usepackage{booktabs}

\usepackage{xcolor}
\usepackage{pgfplots}
\pgfplotsset{compat=1.11}

\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{fit}

\usepackage{varioref}
\usepackage[pdftex]{hyperref}
\usepackage{cleveref}
\usepackage[binary-units=true]{siunitx}
\usepackage{todonotes}

\usepackage[babel]{csquotes}
\usepackage[backend=biber,style=authoryear]{biblatex}

\usepackage{listings}

% color definitions for listings
\definecolor{bluekeywords}{rgb}{0.13,0.13,1}
\definecolor{greencomments}{rgb}{0,0.5,0}
\definecolor{redstrings}{rgb}{0.9,0,0}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstset{literate=
  {á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1
  {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
  {à}{{\`a}}1 {è}{{\`e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1
  {À}{{\`A}}1 {È}{{\'E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1
  {ä}{{\"a}}1 {ë}{{\"e}}1 {ï}{{\"i}}1 {ö}{{\"o}}1 {ü}{{\"u}}1
  {Ä}{{\"A}}1 {Ë}{{\"E}}1 {Ï}{{\"I}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1
  {â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1
  {Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1
  {œ}{{\oe}}1 {Œ}{{\OE}}1 {æ}{{\ae}}1 {Æ}{{\AE}}1 {ß}{{\ss}}1
  {ű}{{\H{u}}}1 {Ű}{{\H{U}}}1 {ő}{{\H{o}}}1 {Ő}{{\H{O}}}1
  {ç}{{\c c}}1 {Ç}{{\c C}}1 {ø}{{\o}}1 {å}{{\r a}}1 {Å}{{\r A}}1
  {€}{{\EUR}}1 {£}{{\pounds}}1
}

\newcommand{\listingpartial}{\mbox{$\partial$}}

%\lstdefinestyle{csharp}{
%	language=[Sharp]C,
%}

\lstdefinestyle{matlab}{
	language=matlab,
	showspaces=false,
	showtabs=false,
	breaklines=true,
	showstringspaces=false,
	breakatwhitespace=true,
	escapeinside={/*@}{@*/},
	backgroundcolor=\color{backcolour},  
	commentstyle=\color{greencomments},
	keywordstyle=\color{bluekeywords}\bfseries,
	stringstyle=\color{redstrings},
	basicstyle=\footnotesize\ttfamily,
	columns=fullflexible,
	tabsize=2,
	numbers=left,                    
    numbersep=5pt,
    numberblanklines=true,
    morekeywords={syms,pretty}
}

% cleveref bindings for other packages
\crefname{lstlisting}{listing}{listings}
\Crefname{lstlisting}{Listing}{Listings}

\bibliography{quellen.bib}

\geometry{a4paper,
		top=25mm, 
		left=40mm, 
		right=25mm, 
		bottom=30mm, 
		headsep=10mm, 
		footskip=12mm}

\graphicspath{ {./images/}{./images/source/} }

\pagestyle{plain}
\pagenumbering{arabic}

% Generate the index and glossary
\makeindex

\newcommand{\name}[1]{\textsc{#1}}
\newcommand{\algo}[1]{\textit{#1}}
\newcommand{\acro}[1]{\texttt{#1}}
\newcommand{\imgfile}[1]{\texttt{#1}}

% math commands
\renewcommand{\vec}{\vectorsym}
\newcommand{\mat}{\matrixsym}
\newcommand{\transp}{^{\mathstrut\scriptscriptstyle{\top}}}
\DeclareMathOperator*{\argmin}{\arg\!\min}
\newcommand{\thetavec}{\ensuremath{\vec{\theta}}}
\newcommand{\order}[1]{\ensuremath{\mathcal{O}(#1)}}

% "SI" units
\sisetup{detect-weight=true, detect-family=true}
\DeclareSIUnit	\px{px}

\begin{titlepage}
	\title{\textbf{Large Scale Image Retrieval} \\ Using Features Extracted From \\ Mobile Phone Camera Stills}
	\author{Markus Mayer}
	\date{\today}
\end{titlepage}

\begin{document}

%Term definitions
%\newglossaryentry{sse}{name=SSE, description={Sum of Squared Errors}}

\maketitle

\begin{abstract}
Like regular \textit{Image Retrieval}, but on a larger scale.
\end{abstract}

\tableofcontents
\clearpage

\section{Bildvorverarbeitung}

\subsection{Cropping und Resampling}

\todo[inline]{Da die Ausgangsbilder im Wesentlichen aus (zum Großteil freigestellten) Produkt-Werbefotos bestehen ...}

\begin{figure}
	\centering
\begin{tikzpicture}
    
	\node[inner sep=0pt] (product) at (0,0)
    	{\includegraphics[width=.5\textwidth]{7A5F52750ADD07483305B0C2226A484ED74B42FD4D87B4BBBC352DCF4E8D8BB8}};
    	
	\draw[<->,shorten <= 1pt] (product.north west) -- (product.north east)
	    node[midway,fill=white] {\SI{1200}{\px}};    	
	\draw[<->,shorten <= 1pt] (product.north west) -- (product.south west)
	    node[rotate=90,midway,fill=white] {\SI{1450}{\px}};

	\coordinate (GL) at (product.south west);
	\coordinate (GR) at (product.south east);

	\coordinate (GT) at (product.north east);
	\coordinate (GB) at (product.south east);

	\coordinate (PL) at ($(GL)!115/1200!(GR)$);
	\coordinate (PR) at ($(GL)!1114/1200!(GR)$);

	\coordinate (PT) at ($(GT)!496/1450!(GB)$);
	\coordinate (PB) at ($(GT)!999/1450!(GB)$);

	\draw[<->] (PL) -- (PR)
	    node[midway,fill=white] {\SI{1009}{\px}};

	\draw[<->] (PT) -- (PB)
	    node[rotate=90,midway,fill=white] {\SI{514}{\px}};
	    
	\draw[dotted] (GL) -- (PL);
	\draw[dotted] (PR) -- (GR);
	\draw[dotted] (PB) -- (GR);
	\draw[dotted] (GT) -- (PT);
    	
\end{tikzpicture}
	\caption{Vorverarbeitung: Beispielbild Produktfoto}
	\caption*{Produkt "`Sonnenbrille, Farbverlauf, Leo, Havanna"', Michael Kors, \cite{Conleys:2015:Sonnenbrille:Online}}
	\label{fig:vorverBild}
\end{figure}

Das in \cref{fig:vorverBild} gezeigte Quellbild weist eine Dimension von $\SI{1200}{\px} \times \SI{1450}{\px}$ (Breite $\times$ Höhe) auf, von denen das eigentliche Produktbild jedoch nur ca. $\SI{1009}{\px} \times \SI{514}{\px}$ in Anspruch nimmt.

Würde dieses Bild nun zwecks Verringerung des Speicherbedarfs und der weiteren Verarbeitungszeiten auf eine maximale Kantenlänge von z.B. \SI{512}{\px} heruntergerechnet werden --- dies entspräche $\SI{424}{\px} \times \SI{512}{\px}$ --- so würde das eigentliche Produktbild im resultierenden Format nur noch $\SI{357}{\px} \times \SI{181}{\px}$ beanspruchen.

Durch ein zuvoriges Beschneiden des Bildes auf den relevanten Bildbereich 
-- eine genaue Definition des Begriffes "`relevant"' steht hierbei noch aus -- 
ergäbe sich indes ein Bereich von $\SI{512}{\px} \times \SI{261}{\px}$ für bildwichtige Inhalte.
Diese Vorgehensweise führt in diesem Beispiel folglich zu einer Verdoppelung der nutzbaren Datenmenge gegenüber den naiven Ansatz. \Cref{tab:vorverDimensionen} verdeutlicht die Dimensionen und prozentualen Unterschiede.

\begin{table}
	\centering
	\begin{tabular}{lrrrr}
		\toprule
		Bild & Breite & Höhe & Anzahl Pixel & Anteil Originalgröße \\
		\midrule
		$G_0$ & \SI{1200}{\px} & \SI{1450}{\px} & \SI{1740000}{\px} & \SI{100}{\percent} \\
		$P_0$ & \SI{1009}{\px} & \SI{514}{\px} & \SI{518626}{\px} & \SI{29.81}{\percent} \\
		\midrule
		$G_1$ & \SI{424}{\px} & \textbf{\SI{512}{\px}} & \SI{217088}{\px} & \SI{12.47}{\percent} \\	
		$P_1$ & \SI{357}{\px} & \SI{181}{\px} & \SI{64617}{\px} & \SI{0.04}{\percent} \\
		\midrule
		$G_2, P_2$ & \textbf{\SI{512}{\px}} & \SI{261}{\px} & \SI{133632}{\px} & \SI{0.08}{\percent} \\
		\bottomrule
	\end{tabular}
	\caption{Vorverarbeitung: Bilddimensionen im Vergleich}
	\caption*{$G_0, P_0$: Bereich des Gesamtbildes $G$ und Produktbildes $P$ in den ursprünglichen Dimensionen; $G_1, P_1$: Bereiche nach Verkleinerung der längsten Kante des Bildes $G$ auf \SI{512}{px}; $G_2, P_2$: Bereiche nach Entfernung der bildunwichtigen Randteile in $G$, gefolgt von Reduktion der längsten Kante auf \SI{512}{\px}.}
	\label{tab:vorverDimensionen}
\end{table}

\subsubsection{Energiebasiertes Retargeting}

Bildretargeting befasst sich mit der Aufgabe, ein Bild fester Dimension auf Zielen mit vom Bild unterschiedlicher oder generell variabler Dimension darzustellen, wie es etwa im Rahmen von responsive designs von Webseiten \todo{erklären} oder bei Smartphones beim Wechsel von vertikaler Lage ("`portrait mode"') zu horizontaler Lage ("`landscape mode"') notwendig wird.
%
Ein prominentes, aber nicht mehr all zu oft auftretendes Beispiel für dieses Problem ist die Darstellung von 4:3-Filmformaten auf einem Fernseher mit einem 16:9- oder 16:10-Bildverhältnis, wobei man sich zwischen vollem Bild, aber reduzierter Bildhöhe ("`letterbox"') oder voller Ausnutzung der Höhe der Anzeigefläche, aber fehlenden Bildrändern ("`Pan \& Scan"') entscheiden muss.

Während man einen Text dynamisch entsprechend des zur Darstellung verfügbaren Platzes umbrechen kann, ist dies bei Bildern nicht möglich.
Übliche Optionen in diesen Fällen sind das Beschneiden des Bildes auf die Dimensionen der Anzeigefläche (crop), das Skalieren des Bildes in den neuen Anzeigebereich unter Beachtung des Aspektverhältnisses (zoom, scale to fit), sowie das Skalieren des Bildes ohne Beachtung des Aspektverhältnisses (stretching), wobei jede dieser Optionen ihre eigenen Vor- und Nachteile mit sich bringt.

Ein wünschenswerter Zustand ist es, Bildteile stattdessen entsprechend ihrer Wichtigkeit zu behalten oder zu verwerfen. 
\cite{avidan2007seam} formulieren die "`Wichtigkeit"' eines Pixels als dessen Informationsgehalt, ausgedrückt über die Energie $e_1(\mat I)$ des Bildes $\mat I$:
%
\begin{align}
e_1(\mat I) &= |\frac{\partial}{\partial x} \mat I| + |\frac{\partial}{\partial y} \mat I|
\end{align}
%
Hierbei entsprechen die beiden Teilsummen den partiellen Ableitungen des Bildes in $x$- und $y$-Richtung.

Eine Approximation der Ableitung $\sfrac{\partial f}{\partial x}$ ist der zentrale Differenzenquotient
%
\begin{align}
\frac{\partial f}{\partial x} &\approx \frac{f(x+\Delta x) - f(x-\Delta x)}{2\Delta x} \label{eq:centralDifferenceOperator}
\end{align}
%
der sich bei einer diskreten Schrittweite von $\Delta x = \Delta k = 1$ als Faltung $(f \ast g)[k]$ von $f[k]$ mit der Funktion
\begin{align}
g[k] = 
	\begin{cases}
		-\frac{1}{2} & \text{wenn } k = +1 \\
		+\frac{1}{2} & \text{wenn } k = -1 \\
		0 & \text{sonst}
	\end{cases} \label{eq:conv1DKernel}
\end{align}
%
abbilden lässt.
Die Überkreuzung der Vorzeichen im sog. Faltungskern erklärt sich über die Definition der diskreten Faltung:
%
\begin{align}
(f \ast g)[n] &= \sum_k f[k] \cdot g[n - k] \\
              &= \sum_k f[n - k] \cdot g[k] \label{eq:diskFaltung}
\end{align}

Es zeigt sich, dass diese einer gewichteten Summenbildung der Funktion $f$ mit allen Gewichtswerten $g$ entspricht%
\footnote{Der Umkehrung der Betrachtungsrichtung von $k$ zu $-k$ verdient die Faltung ihren Namen, analog einem gefalzten Blatt, dessen eine Hälfte auf die andere gefaltet wird.}.
Die Variation in \cref{eq:diskFaltung} ergibt sich aus der Kommutativität der Faltungsoperation und ist oft besser geeignet, um Gewichtungen mit einer begrenzten Anzahl an Koeffizienten (z.B. einer finiten Impulsantwort) darzustellen%
\footnote{Die Mächtigkeit der Menge der Gewichtungskoeffizienten $g$ ist im Allgemeinen geringer als die Mächtigkeit der Menge der zu gewichtenden Funktionswerte $f$; Ein FIR-Filter ist üblicherweise "`kürzer"' als das zu filternde Signal.}.

\Cref{eq:comparisonConv1DWithCentralDiff} zeigt die Identität zwischen der Faltung einer Funktion $f[n]$ mit der in \cref{eq:conv1DKernel} dargestellten Funktion $g[n]$:
%
\begin{align}
\label{eq:comparisonConv1DWithCentralDiff}
\begin{split}
(f \ast g)[n] &= \overbrace{f\left[n - \left(-1\right)\right] g[-1]}^{k = -1}
              \,+\, \overbrace{f\left[n - 0\right] g[0]}^{k = 0}
              \,+\, \overbrace{f\left[n - \left(+1\right)\right] g[+1]}^{k = +1} \\
              &= f\left[n + 1\right] \cdot \left(+\frac{1}{2}\right) 
              + f\left[n\right] \cdot (0) 
              + f\left[n - 1\right] \cdot \left(-\frac{1}{2}\right) \\              
              &= \frac{f\left[n + 1\right] - f\left[n - 1\right]}{2}
\end{split}
\end{align}

Bei Darstellung der Funktion $f[n]$ und des Faltungskerns $g[n]$ in vektorieller Form als $\vec f$ und $\mat G$ schreibt sich die Faltung generalisiert auf eine oder zwei Dimensionen als
%
\begin{align}
(f \ast g)(n) = \mat G \ast \vec f
\end{align}
%
Der in \cref{eq:conv1DKernel} beschriebene eindimensionale Faltungskern zur Berechnung des zentralen Differenzenquotienten zur diskreten Approximation des Differentialquotienten gemäß \cref{eq:centralDifferenceOperator} beschreibt sich so als
%
\begin{align}
\mat G = \begin{bmatrix}
 1 & 0 & -1
 \end{bmatrix} \label{eq:len3diffKernel}
\end{align}
%

%
\todo[inline]{Stellt Kanten mit doppelter Breite dar}
\todo[inline]{Darstellung als Stems und Pixelwerte!}
\todo[inline]{Sinnvolle Begründung für zentralen Differenzenquotienten}
\todo[inline]{Intuitive Erklärung für zentralen Differenzenquotienten}
\todo[inline]{Sample und Plots für gefilterte Daten}

\begin{lstlisting}[language=matlab,caption={Eindimensionale Faltung in MATLAB mit Kernel der Länge 2},label=lst:len2diffKernel]
>> sequence = [1 1 1 1 0 1 0 0 0 1 1 1];
>> kernel   = [1 -1];
>> conv(sequence, kernel)
ans =
     1  0  0  0 -1  1 -1  0  0  1  0  0 -1
\end{lstlisting}

\todo{1D-Filterkernel, Differenzoperator}

Diese Form des Filters ist jedoch anfällig gegenüber Störungen (z.B. Sensorrauschen einer aufnehmenden Kamera, Klümpchenbildung der Silberhalogenide im Filmsubstrat, etc.), da diese fälschlicherweise als korrekte Intensitätssprünge gewertet werden.

Es ist allerdings eine valide Annahme \todo{Zitat LION}, dass in nicht-synthetischen Bildern starke Intensitätssprünge zwischen zwei benachbarten Pixeln unwahrscheinlich sind -- "`Natura non facit saltus"': Die Natur macht keine Sprünge -- weswegen das Auftreten einer starken Intensitätsschwankung ebenfalls ein Indikator für überlagerndes Rauschen ist.

Stochastisches Rauschen wird im Allgemeinen durch eine Glättungsoperation gemindert%
\footnote{Wären die Rauschintensitäten exakt vorhersag- und damit korrigierbar, handelt es sich nicht länger um stochastisches, sondern deterministisches Rauschen. Nicht per se glättende Algorithmen wie eine struktur- und texturbasierte Korrektur einzelner statistisch auffälliger Bildintensitäten sind jedoch denkbar.}.
Hierdurch steht jedoch das Detektieren von Sprüngen in Suchrichtung in direktem Widerspruch zur Korrektur des Rauschens in derselben Richtung.

Um dem entgegenzuwirken erweitert der \algo{Sobel-Operator} das Konzept auf zwei Dimensionen in eine Faltungsmatrix (den Filterkernel) und führt die Glättung orthogonal zur Suchrichtung aus, wodurch die Differenzierung nicht länger von ihr beeinträchtigt wird.

Hierbei wird die Differenzierung in (hier: horizontaler) Suchrichtung
%
\begin{align}
\vec{g_x} &= \begin{bmatrix}
	1 & 0 & -1
	\end{bmatrix}
\end{align}
%
mit einer Glättung in orthogonaler (hier: vertikaler) Richtung
%
\begin{align}
\vec{g_y} &= \begin{bmatrix}
	1 \\
	2 \\
	1
	\end{bmatrix}
\end{align}
%
überlagert, so dass sich der zweidimensionale Filterkernel des Sobel-Operators ergibt
%
\begin{align}
\mat G &= \vec{g_y} \cdot \vec{g_x} = \begin{bmatrix}
	1 & 0 & -1 \\
	2 & 0 & -2 \\
	1 & 0 & -1
	\end{bmatrix}
\end{align}
%
Da für die Glättung des aktuellen Intensitätswertes nur Werte in Betracht gezogen werden, die nicht 

Hierbei wird parallel zur Differenzierung in Suchrichtung orthogonal zur Suchrichtung geglättet, um Bildrauschen entgegen zu wirken.

Die Sobel-Operatoren $G_x$ und $G_y$

Als diskrete Approximation der ersten Ableitung des Bildes kann der Sobel-Operator \todo{Quelle} verwendet werden


\section{Übersicht der Literatur}

\cite{orb} beschreiben einen neuen binären Deskriptor genannt \algo{ORB}, der auf \algo{BRIEF} basiert, jedoch um Rotationsinvarianz und Rauschresistenz erweitert wurde. \algo{ORB} ist (bei vergleichbarer Performance) um zwei Magnituden schneller als \acro{SIFT}. Unterstellt dabei, dass \algo{SURF} besser ist als \algo{SIFT}; liefert Quelle für \algo{SURF}.

\cite{eliveindonesia} ist eine Präsentation zum Entwurf eines Nutz"-vieh-Klas"-si"-fi"-ka"-tions"-sys"-tems, das Ansätze zur Parallelisierung von \algo{SIFT} und \algo{SURF} anmerkt. Hierbei werden unter anderem Parallelisierungen der Algorithmen (\algo{Parallel SIFT} und \algo{Parallel SURF}) besprochen, sowie auf Mehrmaschinen-Verarbeitung der Bilder selbst angeht; Hintergrund ist, dass die Features selbst lokaler Natur sind, für die Auswertung also nicht unbedingt der gesamte Kontext des Bildes notwendig ist. Eine Einführung von Padding an den Bildrändern wird ebenfalls erwähnt.

\cite{detmatchkeyproadPresi} vergleichen \algo{SIFT} mit \algo{Affine-SIFT} und anderen (Stichworte \algo{FLANN} und \algo{RANSAC} -- Hinweis: \algo{FLANN} ist auch als Functional Link Neural Network bekannt, meint hier jedoch Fast Linear Approximation of Nearest Neighbors) und weist darauf hin, dass \algo{SIFT} nur in vier Parametern invariant ist: Zoom, Rotation, sowie X- und Y-Translation; affine Transformationen wie Perspektivenänderungen oder Rotation um eine geneigte Kameraachse sind dabei inbegriffen (d.h. gegenüber Kameratilts ist Standard-\algo{SIFT} nicht invariant).

Hinweis auf den "`Curse of dimensionality"' (den "`Fluch der Dimensionalität"'), 
siehe \url{https://en.wikipedia.org/wiki/Curse_of_dimensionality}, zur Begründung,
weswegen Kd-Trees prinzipiell ungeeignet für das Indexieren von \algo{SIFT}-Features ist (diese sind sehr hochdimensional).

\cite{zha2010computer} beschreiben als \cite{zha2010computer_mift} (siehe \url{http://link.springer.com/chapter/10.1007/978-3-642-12304-7_50}) den \algo{MIFT}-Algorithmus "`A Mirror Reflection Invariant Feature Descriptor"'.

Zusätzliche Entwicklung mit \algo{MI-SIFT}.

\cite{alhwarin2011fast} nennt drei neue \algo{SIFT}-Ansätze für schnelleres und robusteres Matching in Robotik-Anwendungen.

\cite{yin2013content} beschreiben Content-Based Image Retrieval mittels Apache Hadoop auf Basis von \algo{SURF}-Deskriptoren und "`Locality-Sensitive Hashing"'.

\cite{lowe2004distinctive} ist das Original-Paper von Lowe zu \algo{SIFT}. Er merkt an, dass verschiedene Detektoren wie z.B. der Harris-Kantendetektor stark auf Bildskalierungen reagieren und demnach ungeeignet sind.

\cite{ginesu2012objective} vergleichen \algo{WebP} mit bestehenden Bildformaten wie \algo{JPEG} und \algo{PNG}.

\section{Section B}




% print the list of figures
\addcontentsline{toc}{section}{List of Figures}
\listoffigures

\printbibliography

\end{document}